namespace AntAlife.Logic
{
    public abstract class Instinct
    {
        //Instinct Layer (ML-driven):
        // Здесь живет наша ML-модель (скорее всего, обученная с помощью Reinforcement Learning - Обучения с Подкреплением).
        // Входные данные (Состояние среды для ML): Что муравей "видит" и "чувствует"? Энергия, здоровье, тип клетки под ногами, феромоны вокруг (Food, Danger, Trail), есть ли рядом еда/враг/стена, направление/расстояние до гнезда, текущий AntState из Brain.
        // Модель ML (Сердце Инстинкта): Натренированная модель (например, нейронная сеть, загруженная через ML.NET), которая по входным данным предсказывает "ценность" (Q-value) каждого возможного действия (Move N, Move E, Move S, Move W, Attack, Pickup, Drop, Rest...).
        // Выходные данные (Instinct.SuggestAction): Метод возвращает предлагаемое действие (например, AntAction.MoveNorth) – то, которое модель считает наиболее выгодным в данный момент для долгосрочного выживания/успеха (получения награды).
        // Brain Layer (State & Role Logic):
        // Получает предложение от Instinct.SuggestAction.
        // Использует свою логику состояний (AntState) и ролей (AntType).
        // Решение: Может либо принять предложение инстинкта, либо отвергнуть/изменить его. Например, инстинкт предлагает идти на север за слабым запахом еды, но Brain видит врага прямо там и решает перейти в состояние Fleeing и бежать на юг. Или инстинкт предлагает случайное блуждание, а Brain знает, что он в состоянии ReturningToNest и переопределяет движение в сторону гнезда.
    }
}